{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision Tree Model on Titanic Survival Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWJ12InM0162iLAF0ChyXI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DevanshParmar/Data-Science-Summer-Camp-2021/blob/main/Decision%20Tree%20Model%20on%20Titanic%20Survival%20Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Scig2d2E9Tf2"
      },
      "source": [
        "## **Decision Tree Model on Titanic Survival Dataset**\n",
        "This is an implementation of the Decision Tree Model, a machine learning model on the Titanic survival dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ohqIXtvId_p"
      },
      "source": [
        "#### **Uploads**\n",
        "Setting up libraries and uploading dataset files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWLIh6DJBb12"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exkGi5yhB4nk",
        "outputId": "8b62b8d9-a8ea-4ada-fce3-a37b8bf1904c"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "%cd /content/gdrive/My Drive/Kaggle\n",
        "!kaggle competitions download -c titanic\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/Kaggle\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "train.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "gender_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "gender_submission.csv  kaggle.json  test.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnbdI_Grl_NZ"
      },
      "source": [
        "#### **Data Preprocessing**\n",
        "Making a function to make changes into the dataframe, such as deleting various unnecessary columns and converting Sex to male=0, female=1 objective case; and filling in median value of Age wherever it is not available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsRFRgZDPt2z",
        "outputId": "59d0921f-0554-4b90-9951-40dafbb1c063"
      },
      "source": [
        "print(\"Input Dataframes:\")\n",
        "data = pd.read_csv('/content/gdrive/MyDrive/Kaggle/train.csv')\n",
        "col_names1 = ['PassId', 'Survived', 'PClass', 'Name', 'Sex', 'Age', 'SibSp', 'ParCh', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
        "data.columns = col_names1\n",
        "print(data.head())\n",
        "print(\" \")\n",
        "\n",
        "test = pd.read_csv('/content/gdrive/MyDrive/Kaggle/test.csv')\n",
        "col_names2 = ['PassId', 'PClass', 'Name', 'Sex', 'Age', 'SibSp', 'ParCh', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
        "test.columns = col_names2\n",
        "print(test.head())\n",
        "print(\" \")\n",
        "\n",
        "test_survived = pd.read_csv('/content/gdrive/MyDrive/Kaggle/gender_submission.csv')\n",
        "test_survived.columns = ['PassId', 'Survived']\n",
        "print(test_survived.head())\n",
        "print(\" \")\n",
        "\n",
        "print(\"Output Dataframes:\")\n",
        "data.pop(\"PassId\")\n",
        "data.pop(\"Name\")\n",
        "data.pop(\"Ticket\")\n",
        "data.pop(\"Cabin\")\n",
        "data.pop(\"Embarked\")\n",
        "data.Sex.replace(('male', 'female'), (0, 1), inplace=True)\n",
        "print(data.head())\n",
        "print(\" \")\n",
        "\n",
        "test.pop(\"PassId\")\n",
        "test.pop(\"Name\")\n",
        "test.pop(\"Ticket\")\n",
        "test.pop(\"Cabin\")\n",
        "test.pop(\"Embarked\")\n",
        "test.Sex.replace(('male', 'female'), (0, 1), inplace=True)\n",
        "test_survived.pop(\"PassId\")\n",
        "test['Survived'] = test_survived.values\n",
        "print(test.head())\n",
        "print(\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Dataframes:\n",
            "   PassId  Survived  PClass  ...     Fare Cabin  Embarked\n",
            "0       1         0       3  ...   7.2500   NaN         S\n",
            "1       2         1       1  ...  71.2833   C85         C\n",
            "2       3         1       3  ...   7.9250   NaN         S\n",
            "3       4         1       1  ...  53.1000  C123         S\n",
            "4       5         0       3  ...   8.0500   NaN         S\n",
            "\n",
            "[5 rows x 12 columns]\n",
            " \n",
            "   PassId  PClass  ... Cabin Embarked\n",
            "0     892       3  ...   NaN        Q\n",
            "1     893       3  ...   NaN        S\n",
            "2     894       2  ...   NaN        Q\n",
            "3     895       3  ...   NaN        S\n",
            "4     896       3  ...   NaN        S\n",
            "\n",
            "[5 rows x 11 columns]\n",
            " \n",
            "   PassId  Survived\n",
            "0     892         0\n",
            "1     893         1\n",
            "2     894         0\n",
            "3     895         0\n",
            "4     896         1\n",
            " \n",
            "Output Dataframes:\n",
            "   Survived  PClass  Sex   Age  SibSp  ParCh     Fare\n",
            "0         0       3    0  22.0      1      0   7.2500\n",
            "1         1       1    1  38.0      1      0  71.2833\n",
            "2         1       3    1  26.0      0      0   7.9250\n",
            "3         1       1    1  35.0      1      0  53.1000\n",
            "4         0       3    0  35.0      0      0   8.0500\n",
            " \n",
            "   PClass  Sex   Age  SibSp  ParCh     Fare  Survived\n",
            "0       3    0  34.5      0      0   7.8292         0\n",
            "1       3    1  47.0      1      0   7.0000         1\n",
            "2       2    0  62.0      0      0   9.6875         0\n",
            "3       3    0  27.0      0      0   8.6625         0\n",
            "4       3    1  22.0      1      1  12.2875         1\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "immomjS2I13A"
      },
      "source": [
        "#### **Decision Tree Functions**\n",
        "In the next three blocks, we define:\n",
        "1. Entropy Function\n",
        "2. Division Algorithm\n",
        "3. Information Gain Function\n",
        "\n",
        "All three of them are important in the study of Decision Trees."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoaCH_nXNEZV"
      },
      "source": [
        "def entropy(target_col):\n",
        "    elements, counts = np.unique(target_col,return_counts = True)\n",
        "    sum = 0.0\n",
        "    n = np.sum(counts)\n",
        "    for i in counts:\n",
        "        p = i/n\n",
        "        sum = sum - (p * np.log2(p))\n",
        "    return sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMN5iiOlfEHX"
      },
      "source": [
        "def division(input_data, title, mean):\n",
        "    right = pd.DataFrame([], columns = input_data.columns)\n",
        "    left = pd.DataFrame([], columns = input_data.columns)\n",
        "    k = input_data.shape[0]\n",
        "    for x in range(k):\n",
        "        value = input_data[title].loc[x]\n",
        "        if value >= mean:\n",
        "            right = right.append(input_data.iloc[x])\n",
        "        else:\n",
        "            left = left.append(input_data.iloc[x])\n",
        "    return right, left"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjFDInCznjsg"
      },
      "source": [
        "def iGain(input_data, title, mean):\n",
        "    right, left = division(input_data, title, mean)\n",
        "    k = input_data.shape[0]\n",
        "    left_ratio = float(left.shape[0])/k\n",
        "    right_ratio = float(right.shape[0])/k\n",
        "    if left.shape[0] == 0 or right.shape[0] == 0:\n",
        "        return -99999\n",
        "    igain = entropy(input_data.Survived) - ( left_ratio * entropy(left.Survived) + right_ratio * entropy(right.Survived))\n",
        "    return igain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVtW3BT7JcZi"
      },
      "source": [
        "#### **Modeling**\n",
        "In the next block we define the decision tree model. \n",
        "1. The first function inside the class initialises the model.\n",
        "2. The second is the main training module.\n",
        "3. The third function is the prediction module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSr7ZXMkg3nL"
      },
      "source": [
        "class DT:\n",
        "    def __init__(self, depth=0, max_depth=5):\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "        self.title_name = None\n",
        "        self.mean_val = None\n",
        "        self.depth = depth\n",
        "        self.max_depth = max_depth\n",
        "        self.target = None\n",
        "    #                              \n",
        "    #                              \n",
        "    def train_model(self, input_train):\n",
        "        features = ['PClass', 'Sex', 'Age', 'SibSp', 'ParCh', 'Fare']             \n",
        "        iGains = []\n",
        "        for col in features: \n",
        "            iGains.append(iGain(input_train, col, input_train[col].mean()))\n",
        "        #                              \n",
        "        self.title_name = features[np.argmax(iGains)]                     \n",
        "        self.mean_val = input_train[self.title_name].mean()  \n",
        "        #                              \n",
        "        r_data, l_data = division(input_train, self.title_name, self.mean_val)   \n",
        "        r_data = r_data.reset_index(drop=True)                    \n",
        "        l_data = l_data.reset_index(drop=True)\n",
        "        #                              \n",
        "        if l_data.shape[0] == 0 or r_data.shape[0] == 0:              \n",
        "            if input_train.Survived.mean() >= 0.5: \n",
        "                self.target = 1                                               \n",
        "            else:                                                                       \n",
        "                self.target = 0\n",
        "            return\n",
        "        #                              \n",
        "        if self.depth >= self.max_depth:                                     \n",
        "            if input_train.Survived.mean() >= 0.5:\n",
        "                self.target = 1\n",
        "            else:\n",
        "                self.target = 0\n",
        "            return\n",
        "        #                              \n",
        "        self.left = DT(self.depth+1,self.max_depth)                   \n",
        "        self.left.train_model(l_data)\n",
        "        self.right = DT(self.depth+1,self.max_depth)                  \n",
        "        self.right.train_model(r_data)\n",
        "        #                              \n",
        "        if input_train.Survived.mean() >= 0.5:\n",
        "            self.target = 1\n",
        "        else:\n",
        "            self.target = 0\n",
        "        return\n",
        "    #                              \n",
        "    #                              \n",
        "    def predictions(self,test_df):                                                     \n",
        "        if test_df[self.title_name] > self.mean_val:\n",
        "            if self.right is None:\n",
        "                return self.target\n",
        "            return self.right.predictions(test_df)\n",
        "        #                              \n",
        "        if test_df[self.title_name] < self.mean_val:\n",
        "            if self.left is None:\n",
        "                return self.target\n",
        "            return self.left.predictions(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCU43sfAr3z9"
      },
      "source": [
        "model = DT()\n",
        "model.train_model(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB1UudDq9CK7"
      },
      "source": [
        "#### **Predictions and Accuracy**\n",
        "In the next two blocks, we have measured the various statistical parameters of our model, such as accuracy, loss, F1 score, sensitivity and precision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGnPeRiR-Duz"
      },
      "source": [
        "def stats(dataset):\n",
        "    prediction = []\n",
        "    for i in range(dataset.shape[0]):\n",
        "        prediction.append(model.predictions(dataset.loc[i]))\n",
        "    prediction = np.array(prediction)\n",
        "    survive_data = np.array(dataset['Survived'])\n",
        "    #                              \n",
        "    loss = 0\n",
        "    f_neg = 0\n",
        "    f_pos = 0 \n",
        "    t_neg = 0\n",
        "    t_pos = 0\n",
        "    #                              \n",
        "    for i, j in zip(prediction, survive_data):\n",
        "        if i == 1 and j == 1:\n",
        "            t_pos+=1\n",
        "        elif i == 1 and j == 0:\n",
        "            f_pos+=1\n",
        "            loss+=1\n",
        "        elif i==0 and j == 1:\n",
        "            f_neg+=1\n",
        "            loss+=1\n",
        "        else:\n",
        "            t_neg+=1\n",
        "    #                              \n",
        "    rec = t_pos / (t_pos + f_neg)\n",
        "    prc = t_pos / (t_pos + f_pos)\n",
        "    acc = (t_pos + t_neg) / (t_pos + t_neg + f_pos + f_neg)\n",
        "    f1s = 2 * prc * rec / (prc + rec)\n",
        "    #                              \n",
        "    print('   Accuracy is {:.2f}%'.format(100*acc))\n",
        "    print('       Loss is',loss)\n",
        "    print('   F1 Score is {:.4f}'.format(f1s))\n",
        "    print('Sensitivity is {:.4f}'.format(rec))\n",
        "    print('  Precision is {:.4f}'.format(prc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt9olaxOAIhY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef95f5e5-e898-41ab-e167-b8c3f8b20270"
      },
      "source": [
        "print(\"Statistics for Training dataset are:\")\n",
        "print(\" \")\n",
        "stats(data)\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "print(\"Statistics for Test dataset are:\")\n",
        "print(\" \")\n",
        "stats(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statistics for Training dataset are:\n",
            " \n",
            "   Accuracy is 85.30%\n",
            "       Loss is 131\n",
            "   F1 Score is 0.7706\n",
            "Sensitivity is 0.7432\n",
            "  Precision is 0.8000\n",
            " \n",
            " \n",
            "Statistics for Test dataset are:\n",
            " \n",
            "   Accuracy is 92.34%\n",
            "       Loss is 32\n",
            "   F1 Score is 0.8841\n",
            "Sensitivity is 0.9313\n",
            "  Precision is 0.8414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot_uNe0_9ijP"
      },
      "source": [
        "#### **References**\n",
        "\n",
        "1. Gagan Panwar's YouTube playlist over the same topic was a great help: www.youtube.com/playlist?list=PL9mhv0CavXYg3KFKct0JnslSwBCpAd_g0\n",
        "2. Some Towards Data Science (TDS) articles were helpful, especially: www.towardsdatascience.com/decision-trees-for-classification-id3-algorithm-explained-89df76e72df1\n",
        "3. This Exsilio blog was greatly helpful in visualing the final statistics of the model: www.blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/"
      ]
    }
  ]
}